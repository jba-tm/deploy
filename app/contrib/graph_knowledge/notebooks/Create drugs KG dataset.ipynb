{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"\\\\\".join(os.path.dirname(os.path.abspath(\"__file__\")).split(\"\\\\\")[0:-1]) + \"\\\\data\\\\Structured data\\\\final_merged_drugs.parquet\", engine=\"fastparquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean, explode, and create a DataFrame for a specific edge\n",
    "def explode_and_create_df(col1, col2, edge_name):\n",
    "    temp_df = df[[col1, col2]].copy()\n",
    "\n",
    "    # Drop rows with null values in either column\n",
    "    temp_df.dropna(subset=[col1, col2], inplace=True)\n",
    "    temp_df = temp_df[temp_df[col2].str.lower() != 'nan']\n",
    "    temp_df = temp_df[temp_df[col2].str.lower() != np.nan]\n",
    "\n",
    "    # Drop duplicates\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Replace consecutive separators with a single separator and split\n",
    "    temp_df[col2] = temp_df[col2].str.replace(r'\\|\\|+', '|', regex=True).str.split('|')\n",
    "\n",
    "    # Explode the DataFrame based on col1 and col2\n",
    "    temp_df = temp_df.explode(col1).explode(col2)\n",
    "\n",
    "    # Remove empty strings if any\n",
    "    temp_df = temp_df[temp_df[col1].str.strip() != '']\n",
    "    temp_df = temp_df[temp_df[col2].str.strip() != '']\n",
    "\n",
    "    # Rename columns and create an edge column\n",
    "    temp_df.rename(columns={col1: 'source', col2: 'target'}, inplace=True)\n",
    "    temp_df['edge'] = edge_name\n",
    "\n",
    "    return temp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean, match, explode, and create a DataFrame\n",
    "def match_explode_and_create_df(source_col, target_col, edge_name):\n",
    "    temp_df = df[[source_col, target_col]].copy()\n",
    "    temp_df.dropna(subset=[source_col, target_col], inplace=True)\n",
    "    temp_df = temp_df[temp_df[target_col].str.lower() != 'nan']\n",
    "    temp_df = temp_df[temp_df[target_col].str.lower() != np.nan]\n",
    "    temp_df.drop_duplicates(inplace=True)\n",
    "    # Split each column by '||' and strip whitespace\n",
    "    temp_df[source_col] = temp_df[source_col].astype(str).str.strip().str.split('\\|\\|')\n",
    "    temp_df[target_col] = temp_df[target_col].astype(str).str.strip().str.split('\\|\\|')\n",
    "\n",
    "    # List to store the new rows\n",
    "    new_rows = []\n",
    "\n",
    "    # Iterate over each row and create matched pairs\n",
    "    for _, row in tqdm(temp_df.iterrows()):\n",
    "        sources = row[source_col]\n",
    "        targets = row[target_col]\n",
    "\n",
    "        #if len(sources) == len(targets):\n",
    "        for source, target in zip(sources, targets):\n",
    "            new_rows.append({'source': source, 'target': target, 'edge': edge_name})\n",
    "\n",
    "    # Create a new DataFrame from the list of new rows\n",
    "    exploded_df = pd.DataFrame(new_rows)\n",
    "\n",
    "    return exploded_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_genes_df(df, source_col, target_col, edge_name, gene_info_cols=None):\n",
    "    # Create a new DataFrame\n",
    "    new_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        source = row[source_col]\n",
    "        target = row[target_col]\n",
    "\n",
    "        # Skip if either source or target is NaN\n",
    "        if pd.isna(source) or pd.isna(target):\n",
    "            continue\n",
    "\n",
    "        # Initialize the gene information string\n",
    "        gene_info = \"\"\n",
    "\n",
    "        # Check if gene information columns are provided\n",
    "        if gene_info_cols:\n",
    "            gene_info_pieces = []\n",
    "            for col in gene_info_cols:\n",
    "                if pd.notna(row[col]):\n",
    "                    gene_info_pieces.append(f\"{col}:- {row[col]}\")\n",
    "            gene_info = \"<br>\".join(gene_info_pieces)\n",
    "\n",
    "        new_row = {\n",
    "            'source': source,\n",
    "            'target': target,\n",
    "            'edge': edge_name,\n",
    "            'Full Gene Name': gene_info\n",
    "        }\n",
    "\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "    return pd.DataFrame(new_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3915it [00:00, 15233.56it/s]\n",
      "3645it [00:00, 15338.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# Explode the specified columns with cleaning\n",
    "synonyms_df = explode_and_create_df('name','synonym', 'has synonym')\n",
    "diseases_df = explode_and_create_df('name','Treated Diseases/Conditions', 'used for')\n",
    "side_effects_df = explode_and_create_df('name','Side effects', 'has side effect')\n",
    "kingdom_df = explode_and_create_df('name','kingdom', 'Kingdom')\n",
    "supclass_df = explode_and_create_df('name','subclass', 'Subclass')\n",
    "superclass_df = explode_and_create_df('name','superclass', 'Superclass')\n",
    "class_df = explode_and_create_df('name','class', 'Class')\n",
    "marketed_name_df = explode_and_create_df('name', 'medicine name', 'marketed name')\n",
    "manufacturer_df = match_explode_and_create_df('medicine name', 'manufacturer', 'manufacturer')\n",
    "#medicine_source_df = match_explode_and_create_df('medicine name', 'medicine source', 'source')\n",
    "country_df = match_explode_and_create_df('manufacturer', 'Country of manufacture', 'country')\n",
    "gene_info_columns = ['Name', 'GenBank Protein ID', 'GenBank Gene ID', 'UniProt ID', 'Uniprot Title', 'GenAtlas ID']\n",
    "gene_name_df = create_genes_df(df, 'name', 'Gene Name', 'Targets gene', gene_info_cols=gene_info_columns)\n",
    "species_df = create_genes_df(df, 'name', 'Species', 'Effective in species', gene_info_cols=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all DataFrames\n",
    "knowledge_graph = pd.concat([synonyms_df, diseases_df, side_effects_df, kingdom_df, supclass_df, superclass_df, class_df, marketed_name_df, manufacturer_df, country_df, gene_name_df, species_df])\n",
    "# Merge the 'description' column from df into knowledge_graph on 'name' and 'source'\n",
    "knowledge_graph = knowledge_graph.merge(df[['name', 'description']], left_on='source', right_on='name', how='left')\n",
    "\n",
    "\n",
    "# Drop the extra 'name' column if not needed\n",
    "knowledge_graph.drop('name', axis=1, inplace=True)\n",
    "knowledge_graph.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Drop rows where source equals target for 'has synonym' relationship\n",
    "condition = (knowledge_graph['source'] == knowledge_graph['target']) & (knowledge_graph['edge'] == 'has synonym')\n",
    "knowledge_graph = knowledge_graph.drop(knowledge_graph[condition].index)\n",
    "knowledge_graph.reset_index(inplace=True, drop=True)\n",
    "# Save the knowledge graph to a new CSV file\n",
    "knowledge_graph.to_parquet(\"\\\\\".join(os.path.dirname(os.path.abspath(\"__file__\")).split(\"\\\\\")[0:-1]) + \"\\\\data\\\\Structured data\\\\knowledge_graph.parquet\", engine=\"fastparquet\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
